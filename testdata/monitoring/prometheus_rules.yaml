apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: story-rules
spec:
  groups:
  - name: recording.rules
    rules:
    - record: requests_total
      expr: http_requests_total{code="200"} > 0
    - record: count:up1
      expr: count without(instance, pod, node) (up == 1)
  - name: alerting rules
    rules:
    - alert: KubePodNotReady
      expr: sum by(namespace, pod) (max by(namespace, pod) (kube_pod_status_phase{job="kube-state-metrics",namespace=~"(test.*)",phase=~"Pending|Unknown"}) * on(namespace, pod) group_left(owner_kind) max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"})) > 0
      for: 5m
      labels:
        severity: critical
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 5 minutes.
    - alert: Watchdog
      expr: vector(1)
      labels:
        severity: none
      annotations:
        message: This is an alert meant to ensure that the entire alerting pipeline is functional.
    - alert: TargetDown
      expr: 100 * (count by(job, namespace, service) (up == 0) / count by(job, namespace, service) (up)) > 10
      for: 1m
      labels:
        severity: warning
      annotations:
        message: '{{ printf "%.4g" $value }}% of the {{ $labels.job }}/{{ $labels.service }} targets in {{ $labels.namespace }} namespace are down.'